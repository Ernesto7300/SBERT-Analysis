{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06e28494-b78f-4b21-95c5-404c8c4fca38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (5.1.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\biempi01\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 5.1.2\n",
      "    Uninstalling sentence-transformers-5.1.2:\n",
      "      Successfully uninstalled sentence-transformers-5.1.2\n",
      "Successfully installed sentence-transformers-5.2.0\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "439ec777-c71e-49c7-baeb-599822399c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c2ddc87-a411-4a9e-8be5-bcb20c0c7b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n",
      "tensor([[1.0000, 0.7738],\n",
      "        [0.7738, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# The Socrates vs. Galileo Fight ¬°¬°\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"Todos los cuerpos caen a la misma velocidad.\",\n",
    "    \"Los cuerpos mas pesados caen mas r√°pido.\",\n",
    "   ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acabffde-4470-4fbd-988a-15d31df3babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n",
      "tensor([[1.0000, 0.4054],\n",
      "        [0.4054, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"Todos los cuerpos caen a la misma velocidad.\",\n",
    "    \"La fotos√≠ntesis ocurre en los cloroplastos.\",\n",
    "   ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9127c36d-e670-440f-909e-d1c80b2389d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n",
      "tensor([[1.0000, 0.4868],\n",
      "        [0.4868, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "       \"Todos los cuerpos caen a la misma velocidad.\",\n",
    "    \"En ausencia de rozamiento, todos los objetos caen igual.\",\n",
    "   ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c03f30-1469-450a-9017-b45354b3491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n",
      "tensor([[1.0000, 0.9157],\n",
      "        [0.9157, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "sentences = [\n",
    "    \"Todos los cuerpos caen a la misma velocidad.\",\n",
    "    \"No es cierto que todos los cuerpos caigan a la misma velocidad.\",\n",
    "   ]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "\n",
    "\n",
    "# Es la proyecci√≥n angular entre dos vectores.  \n",
    "# No mide verdad, correcci√≥n cient√≠fica ni coherencia l√≥gica. Solo mide proximidad sem√°ntica aprendida estad√≠sticamente.\n",
    "\n",
    "# Cuando el objetivo es: b√∫squeda / clustering el m√©todo es bueno\n",
    "# Pero para detecci√≥n de contradicciones / consistencia l√≥gica ‚Üí este enfoque es insuficiente\n",
    "# Explorar: modelos entrenados para NLI (entailment / contradiction) o o razonamiento expl√≠cito (LLMs con prompting controlado)\n",
    "\n",
    "# https://www.sbert.net/docs/pretrained-models/nli-models.html\n",
    "# Ver https://huggingface.co/papers/1705.02364 y https://arxiv.org/abs/1705.02364\n",
    "# https://github.com/huggingface/sentence-transformers/blob/main/examples/sentence_transformer/training/nli/training_nli.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5dbf4c6-0c84-42b4-8cdf-1ca196de2810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome\n",
      " - The dog plays in the garden   : 0.0543\n",
      " - The new movie is so great     : 0.8939\n",
      " - A woman watches TV            : -0.0502\n",
      "The cat sits outside\n",
      " - The dog plays in the garden   : 0.2838\n",
      " - The new movie is so great     : -0.0029\n",
      " - A woman watches TV            : 0.1310\n",
      "A man is playing guitar\n",
      " - The dog plays in the garden   : 0.2277\n",
      " - The new movie is so great     : -0.0136\n",
      " - A woman watches TV            : -0.0327\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = [\n",
    "    \"The new movie is awesome\",\n",
    "    \"The cat sits outside\",\n",
    "    \"A man is playing guitar\",\n",
    "]\n",
    "\n",
    "sentences2 = [\n",
    "    \"The dog plays in the garden\",\n",
    "    \"The new movie is so great\",\n",
    "    \"A woman watches TV\",\n",
    "]\n",
    "\n",
    "# Compute embeddings for both lists\n",
    "embeddings1 = model.encode(sentences1)\n",
    "embeddings2 = model.encode(sentences2)\n",
    "\n",
    "# Compute cosine similarities\n",
    "similarities = model.similarity(embeddings1, embeddings2)\n",
    "\n",
    "# Output the pairs with their score\n",
    "for idx_i, sentence1 in enumerate(sentences1):\n",
    "    print(sentence1)\n",
    "    for idx_j, sentence2 in enumerate(sentences2):\n",
    "        print(f\" - {sentence2: <30}: {similarities[idx_i][idx_j]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2e8dc5a-e2f7-498e-94f0-f5fd58244074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.6660, 0.1046],\n",
      "        [0.6660, 1.0000, 0.1411],\n",
      "        [0.1046, 0.1411, 1.0000]])\n",
      "manhattan\n",
      "tensor([[ -0.0000, -12.6269, -20.2167],\n",
      "        [-12.6269,  -0.0000, -20.1288],\n",
      "        [-20.2167, -20.1288,  -0.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, SimilarityFunction\n",
    "\n",
    "# Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Embed some sentences\n",
    "sentences = [\n",
    "    \"The weather is lovely today.\",\n",
    "    \"It's so sunny outside!\",\n",
    "    \"He drove to the stadium.\",\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "\n",
    "\n",
    "# Change the similarity function to Manhattan distance\n",
    "model.similarity_fn_name = SimilarityFunction.MANHATTAN\n",
    "print(model.similarity_fn_name)\n",
    "\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf1cb91-bd45-4daa-8fd1-b6c87b66dbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce304ed9d07b4157a937397c35147677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/734 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Biempi01\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Biempi01\\.cache\\huggingface\\hub\\models--joeddav--xlm-roberta-large-xnli. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4474021bf8124ea292e6ff200f3ccead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Modelo NLI multiling√ºe (incluye espa√±ol)\n",
    "clf = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"joeddav/xlm-roberta-large-xnli\",\n",
    "    tokenizer=\"joeddav/xlm-roberta-large-xnli\",\n",
    "    return_all_scores=True,\n",
    ")\n",
    "\n",
    "premise = \"Todos los cuerpos caen a la misma velocidad.\"\n",
    "hypothesis = \"Los cuerpos mas pesados caen mas r√°pido.\"\n",
    "\n",
    "# Para NLI: premise + hypothesis\n",
    "out = clf({\"text\": premise, \"text_pair\": hypothesis})[0]\n",
    "\n",
    "# Ordenar por score y mostrar\n",
    "out_sorted = sorted(out, key=lambda x: x[\"score\"], reverse=True)\n",
    "for r in out_sorted:\n",
    "    print(f\"{r['label']:>12}: {r['score']:.4f}\")\n",
    "\n",
    "# Utiliza un modelo muy pesado ¬°¬°¬°¬°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d9d6ee6-f878-4ed1-966a-bdf4bb189270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empiezo descarga tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbf1c668fe74cc38325717d845af12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17e53930b62243d6bbe8dcbafb818453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9747ca78cb46aeb9abb9314a688675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba60bd2a11f49c6acb9cd642f8504e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bcfad6b8a446c0bd02c2312fc3135a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer descargado en 44.0 s\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "print(\"Empiezo descarga tokenizer...\")\n",
    "t0 = time.time()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(\"Tokenizer descargado en\", round(time.time() - t0, 1), \"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5e1e2b1-92fb-45c6-bd31-918ce401763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado en 2.2 s\n",
      "      NEUTRAL: 0.9993\n",
      "   ENTAILMENT: 0.0004\n",
      "CONTRADICTION: 0.0003\n"
     ]
    }
   ],
   "source": [
    "import os, time, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "premise = \"Todos los cuerpos caen a la misma velocidad.\"\n",
    "hypothesis = \"Los cuerpos mas pesados caen mas r√°pido.\"\n",
    "\n",
    "t0 = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "print(\"Modelo cargado en\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
    "\n",
    "# OJO: este modelo suele usar el orden [contradiction, neutral, entailment]\n",
    "labels = [\"CONTRADICTION\", \"NEUTRAL\", \"ENTAILMENT\"]\n",
    "\n",
    "for lab, p in sorted(zip(labels, probs), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{lab:>13}: {p:.4f}\")\n",
    "\n",
    "\n",
    "# CONTRADICTION alto ‚Üí el modelo detecta incompatibilidad textual (esperable aqu√≠).\n",
    "# NEUTRAL alto ‚Üí el modelo no ve contradicci√≥n ‚Äúl√≥gica‚Äù clara (pasa con frases ambiguas).\n",
    "# ENTAILMENT alto ‚Üí algo raro (o frase mal tokenizada / hip√≥tesis distinta).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55de4002-66c3-4e5c-af0d-6b88e091de75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado en 2.1 s\n",
      "      NEUTRAL: 0.9967\n",
      "   ENTAILMENT: 0.0018\n",
      "CONTRADICTION: 0.0015\n"
     ]
    }
   ],
   "source": [
    "{0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
    "{'contradiction': 2, 'entailment': 0, 'neutral': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd63d801-cca4-426d-a4e7-e306a2e0ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'entailment', 1: 'neutral', 2: 'contradiction'}\n",
      "{'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label)\n",
    "print(model.config.label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "00f56157-457a-4b8e-a333-31a9dabfc5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado en 2.3 s\n",
      "      NEUTRAL: 0.8617\n",
      "   ENTAILMENT: 0.1354\n",
      "CONTRADICTION: 0.0029\n"
     ]
    }
   ],
   "source": [
    "# Las etiquetas son correctas y el modelo no detecta la contradicci√≥n evidente\n",
    "\n",
    "import os, time, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "premise = \"Ning√∫n cuerpo, independientemente de su peso, cae m√°s r√°pido que otro.\"\n",
    "hypothesis = \"Algunos cuerpos m√°s pesados caen m√°s r√°pido que otros.\"\n",
    "\n",
    "t0 = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "print(\"Modelo cargado en\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
    "\n",
    "# OJO: este modelo suele usar el orden [contradiction, neutral, entailment]\n",
    "labels = [\"CONTRADICTION\", \"NEUTRAL\", \"ENTAILMENT\"]\n",
    "\n",
    "for lab, p in sorted(zip(labels, probs), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{lab:>13}: {p:.4f}\")\n",
    "\n",
    "\n",
    "# CONTRADICTION alto ‚Üí el modelo detecta incompatibilidad textual (esperable aqu√≠).\n",
    "# NEUTRAL alto ‚Üí el modelo no ve contradicci√≥n ‚Äúl√≥gica‚Äù clara (pasa con frases ambiguas).\n",
    "# ENTAILMENT alto ‚Üí algo raro (o frase mal tokenizada / hip√≥tesis distinta).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1077acef-8943-4934-858f-06fca64a4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado en 2.1 s\n",
      "      NEUTRAL: 0.9766\n",
      "CONTRADICTION: 0.0117\n",
      "   ENTAILMENT: 0.0117\n"
     ]
    }
   ],
   "source": [
    "import os, time, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
    "\n",
    "#premise = \"All bodies, regardless of their weight, fall at the same speed.\"\n",
    "#hypothesis = \"Heavier bodies fall at a higher speed.\"\n",
    "\n",
    "#premise = \"For any two bodies with different weights, both fall at the same speed.\"\n",
    "#hypothesis = \"There exists at least one pair of bodies with different weights such that the heavier one falls faster.\"\n",
    "\n",
    "premise = \"In a vacuum, all bodies fall at the same speed, regardless of their weight.\"\n",
    "hypothesis = \"In a vacuum, heavier bodies fall at a higher speed.\"\n",
    "\n",
    "t0 = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()\n",
    "print(\"Modelo cargado en\", round(time.time() - t0, 1), \"s\")\n",
    "\n",
    "inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
    "\n",
    "# OJO: este modelo suele usar el orden [contradiction, neutral, entailment]\n",
    "labels = [\"CONTRADICTION\", \"NEUTRAL\", \"ENTAILMENT\"]\n",
    "\n",
    "for lab, p in sorted(zip(labels, probs), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{lab:>13}: {p:.4f}\")\n",
    "\n",
    "\n",
    "# CONTRADICTION alto ‚Üí el modelo detecta incompatibilidad textual (esperable aqu√≠).\n",
    "# NEUTRAL alto ‚Üí el modelo no ve contradicci√≥n ‚Äúl√≥gica‚Äù clara (pasa con frases ambiguas).\n",
    "# ENTAILMENT alto ‚Üí algo raro (o frase mal tokenizada / hip√≥tesis distinta)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcbe6f4e-866f-4b18-bf8d-59ec3f2d2a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepieceNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 0.8/1.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.1/1.1 MB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe005ac-2193-4fef-9305-bdca5d452bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "¬øPor qu√© el modelo insiste en NEUTRAL?\n",
    "\n",
    "Porque NLI no est√° evaluando f√≠sica ni leyes universales, sino esta pregunta: ‚ÄúSi la premisa es verdadera, ¬øla hip√≥tesis es necesariamente falsa?‚Äù\n",
    "\n",
    "Y el modelo ha aprendido (de millones de ejemplos humanos) que:frases cient√≠ficas pueden estar mal formuladas\n",
    "\n",
    "‚Äúfall at the same speed‚Äù puede interpretarse como: misma velocidad inicial. misma velocidad media, mismo r√©gimen idealizado\n",
    "\n",
    "incluso con ‚Äúin a vacuum‚Äù, el corpus no penaliza con fuerza la contradicci√≥n\n",
    "\n",
    "üëâ El modelo prefiere ser conservador y declarar neutral antes que cometer una falsa contradicci√≥n.\n",
    "\n",
    "Esto es deliberado en su entrenamiento.\n",
    "\n",
    "3Ô∏è‚É£ Conclusi√≥n fuerte (la que importa para tu uso real)\n",
    "\n",
    "Has demostrado emp√≠ricamente que: Los modelos NLI gen√©ricos NO sirven para detectar contradicciones cient√≠ficas o f√≠sicas si la contradicci√≥n depende de supuestos te√≥ricos.\n",
    "\n",
    "Sirven para: contradicciones textuales, negaciones expl√≠citas. cuantificadores simples bien alineados. reformulaciones obvias\n",
    "\n",
    "No sirven para: leyes f√≠sicas. consistencia cient√≠fica. ‚Äúesto viola un principio‚Äù contradicci√≥n por modelo del mundo\n",
    "\n",
    "Si el objetivo es detectar incoherencias del tipo ‚Äúesto viola una ley‚Äù, necesitas una capa adicional:\n",
    "\n",
    "Opci√≥n A ‚Äî NLI + reglas expl√≠citas\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "detectar patrones tipo\n",
    "(\"regardless of weight\" AND \"fall at same speed\")\n",
    "\n",
    "y comparativos opuestos\n",
    "(\"heavier\" AND \"higher speed\")\n",
    "‚Üí marcar contradicci√≥n por regla, no por NLI\n",
    "\n",
    "Opci√≥n B ‚Äî LLM con razonamiento expl√≠cito\n",
    "\n",
    "Un LLM grande, con prompt tipo:\n",
    "\n",
    "‚ÄúAssume classical mechanics in vacuum. Are these two statements compatible?‚Äù\n",
    "\n",
    "Eso ya no es NLI, es razonamiento guiado.\n",
    "\n",
    "Opci√≥n C ‚Äî Formalizaci√≥n (si quieres ser extremo)\n",
    "\n",
    "Traducir a l√≥gica:\n",
    "\n",
    "‚àÄw‚ÇÅ,w‚ÇÇ : v(w‚ÇÅ)=v(w‚ÇÇ)\n",
    "\n",
    "‚àÉw‚ÇÅ>w‚ÇÇ : v(w‚ÇÅ)>v(w‚ÇÇ)\n",
    "\n",
    "Ah√≠ la contradicci√≥n es trivial, pero eso est√° fuera del alcance de NLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85f84f-a7f7-4633-81d3-334bcf3e190d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
